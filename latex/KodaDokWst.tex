\input{style.tex}

\title{Kompresja Danych \\ \Huge{Kodowanie różnicowe + koder Huffmana} \\ \Large{Dokumentacja wstępna} }
\author{ Piotr Chmielewski \\ Michał Dobrzański \\ Maciej Janusz Krajsman \\ Marcin Lembke \\ \\ Politechnika Warszawska, \\ Wydział Elektroniki i Technik Informacyjnych.}

\begin{document}
\maketitle    

\section{Założenia projektowe}
\label{sec:zalozenia_projektowe}

\subsection{Zadanie projektowe}
\label{subsec:zadanie_projektowe}
Opracować algorytm kodowania predykcyjnego (pozycje \cite{Przelaskowski}, \cite{Sayood} literatury uzupełniającej do wykładu) danych dwuwymiarowych wykorzystując do predykcji: lewego sąsiada, górnego sąsiada, medianę lewego, lewego-górnego, górnego sąsiada. Wyznaczyć histogramy danych różnicowych dla danych wejściowych o rozkładzie równomiernym, normalnym, Laplace'a oraz wybranych obrazów testowych. Zakodować dane różnicowe przy użyciu klasycznego algorytmu Huffmana. Wyznaczyć entropię danych wejściowych i różnicowych, porównać ze średnią długością bitową kodu wyjściowego. Ocenić efektywność algorytmu do kodowania obrazów naturalnych. 

\subsection{Narzędzia programistyczne}
\label{subsec:narzedzia_programistyczne}
Projekt napisany zostanie w~języku Python, z~użyciem potrzebnych bibliotek (np. $Pillow$~---~konkretne decyzje w~tej kwestii zapadną na etapie implementacji). Wykorzystane zostanie środowisko $JetBrains$ $PyCharm$ Community Edition.

\section{Metody kodowania}
\label{sec:metody}

\subsection{Kodowanie predykcyjne}
\label{subsec:kodowanie_roznicowe}

Kodowanie predykcyjne pozwala zredukować rozmiar danych dzięki wykorzystaniu wiedzy o~już przetworzonej części informacji. 

\subsection{Kodowanie  Huffmana}
\label{subsec:kod_huffamana}

Kodowanie Huffmana jest bezstratną metodą, pozwalającą otrzymać efektywny kod symboli. Uzyskany kod jest optymalnym kodem prefiksowym, tj. nie istnieje żaden inny kod w~tej kategorii, który zapewniałby mniejszą średnią długość słowa kodowego. Idea tej metody opiera się na dwóch założeniach:

\begin{enumerate} \itemsep1pt
	\item Długość słowa kodowego dla danego symbolu jest tym mniejsza, im częściej występuje on w~alfabecie;
	\item Dwa symbole o~najmniejszej częstości występowania w~alfabecie mają słowa kodowe o~równej długości.
\end{enumerate}

\section{Testowanie}
\label{sec:testowanie}

\subsection{Metody oceny efektywności kompresji danych}
\label{subsec:metody_oceny_efektywnosci_kompresji_danych}
Ocena efektywności zaimplementowanych metod kodowania polegać będzie na porównaniu:
\begin{itemize} \itemsep1pt
	\item entropii
	\item średniej długości słowa kodowego
\end{itemize}
danych wejściowych i~wyjściowych dla różnych obrazów testowych. Zaprezentowane zostaną również histogramy ich oraz danych różnicowych dla każdej metody kodowania.

\subsection{Dane testowe}
\label{subsec:dane_testowe}

Zbiór danych testowych będzie składał się z~kilku obrazów naturalnych, a~także wygenerowanych przez program trzech losowych obrazów, których wartości natężeń pikseli reprezentować będą:

\begin{itemize} \itemsep1pt
	\item rozkład równomierny (równoważny szumowi białemu)
	\item rozkład normalny (Gaussa)
	\item rozkład Laplace'a
\end{itemize}

\input{bibl.tex}
\end{document}

